{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124ff4df-8cc7-4d05-8584-d5b83d80bf3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T13:21:50.439764Z",
     "iopub.status.busy": "2026-01-04T13:21:50.439340Z",
     "iopub.status.idle": "2026-01-04T13:21:50.730722Z",
     "shell.execute_reply": "2026-01-04T13:21:50.729155Z",
     "shell.execute_reply.started": "2026-01-04T13:21:50.439734Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Callable\n",
    "from dotenv import load_dotenv\n",
    "from ollama import chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fceb7201-50d3-4c23-a156-1c6de5a4c0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T13:21:57.600921Z",
     "iopub.status.busy": "2026-01-04T13:21:57.600414Z",
     "iopub.status.idle": "2026-01-04T13:21:58.029844Z",
     "shell.execute_reply": "2026-01-04T13:21:58.028139Z",
     "shell.execute_reply.started": "2026-01-04T13:21:57.600876Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m load_dotenv()\n\u001b[1;32m      3\u001b[0m NUM_RUNS_TIMES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      5\u001b[0m DATA_FILES: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 6\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_docs.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "NUM_RUNS_TIMES = 5\n",
    "\n",
    "DATA_FILES: List[str] = [\n",
    "    os.path.join(os.path.dirname(__file__), \"data\", \"api_docs.txt\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956371c273af5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus_from_files(paths: List[str]) -> List[str]:\n",
    "    corpus: List[str] = []\n",
    "    for p in paths:\n",
    "        if os.path.exists(p):\n",
    "            try:\n",
    "                with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                    corpus.append(f.read())\n",
    "            except Exception as exc:\n",
    "                corpus.append(f\"[load_error] {p}: {exc}\")\n",
    "        else:\n",
    "            corpus.append(f\"[missing_file] {p}\")\n",
    "    return corpus\n",
    "\n",
    "\n",
    "# Load corpus from external files (simple API docs). If missing, fall back to inline snippet\n",
    "CORPUS: List[str] = load_corpus_from_files(DATA_FILES)\n",
    "\n",
    "QUESTION = (\n",
    "    \"Write a Python function `fetch_user_name(user_id: str, api_key: str) -> str` that calls the documented API \"\n",
    "    \"to fetch a user by id and returns only the user's name as a string.\"\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: Fill this in!\n",
    "# YOUR_SYSTEM_PROMPT = \"\"\n",
    "YOUR_SYSTEM_PROMPT = \"\"\"You are a Python code generator who uses provided API documentation to write functions.\n",
    "\n",
    "Rules:\n",
    "1. Use ONLY the context information provided\n",
    "2. Follow the exact API specifications shown in the documentation\n",
    "3. Include necessary imports\n",
    "4. Handle authentication exactly as documented\n",
    "5. Return only what the task specifies\n",
    "\n",
    "Generate clean, functional Python code based on the given API documentation.\"\"\"\n",
    "\n",
    "\n",
    "# For this simple example\n",
    "# For this coding task, validate by required snippets rather than exact string\n",
    "REQUIRED_SNIPPETS = [\n",
    "    \"def fetch_user_name(\",\n",
    "    \"requests.get\",\n",
    "    \"/users/\",\n",
    "    \"X-API-Key\",\n",
    "    \"return\",\n",
    "]\n",
    "\n",
    "\n",
    "def YOUR_CONTEXT_PROVIDER(corpus: List[str]) -> List[str]:\n",
    "    \"\"\"TODO: Select and return the relevant subset of documents from CORPUS for this task.\n",
    "\n",
    "    For example, return [] to simulate missing context, or [corpus[0]] to include the API docs.\n",
    "    \"\"\"\n",
    "    # Return all available corpus documents to provide full API documentation context\n",
    "    # return []\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def make_user_prompt(question: str, context_docs: List[str]) -> str:\n",
    "    if context_docs:\n",
    "        context_block = \"\\n\".join(f\"- {d}\" for d in context_docs)\n",
    "    else:\n",
    "        context_block = \"(no context provided)\"\n",
    "    return (\n",
    "        f\"Context (use ONLY this information):\\n{context_block}\\n\\n\"\n",
    "        f\"Task: {question}\\n\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"- Use the documented Base URL and endpoint.\\n\"\n",
    "        \"- Send the documented authentication header.\\n\"\n",
    "        \"- Raise for non-200 responses.\\n\"\n",
    "        \"- Return only the user's name string.\\n\\n\"\n",
    "        \"Output: A single fenced Python code block with the function and necessary imports.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_code_block(text: str) -> str:\n",
    "    \"\"\"Extract the last fenced Python code block, or any fenced code block, else return text.\"\"\"\n",
    "    # Try ```python ... ``` first\n",
    "    m = re.findall(r\"```python\\n([\\s\\S]*?)```\", text, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m[-1].strip()\n",
    "    # Fallback to any fenced code block\n",
    "    m = re.findall(r\"```\\n([\\s\\S]*?)```\", text)\n",
    "    if m:\n",
    "        return m[-1].strip()\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def test_your_prompt(system_prompt: str, context_provider: Callable[[List[str]], List[str]]) -> bool:\n",
    "    \"\"\"Run up to NUM_RUNS_TIMES and return True if any output matches EXPECTED_OUTPUT.\"\"\"\n",
    "    context_docs = context_provider(CORPUS)\n",
    "    user_prompt = make_user_prompt(QUESTION, context_docs)\n",
    "\n",
    "    for idx in range(NUM_RUNS_TIMES):\n",
    "        print(f\"Running test {idx + 1} of {NUM_RUNS_TIMES}\")\n",
    "        response = chat(\n",
    "            model=\"llama3.1:8b\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            options={\"temperature\": 0.0},\n",
    "        )\n",
    "        output_text = response.message.content\n",
    "        code = extract_code_block(output_text)\n",
    "        missing = [s for s in REQUIRED_SNIPPETS if s not in code]\n",
    "        if not missing:\n",
    "            print(output_text)\n",
    "            print(\"SUCCESS\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Missing required snippets:\")\n",
    "            for s in missing:\n",
    "                print(f\"  - {s}\")\n",
    "            print(\"Generated code:\\n\" + code)\n",
    "    return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_your_prompt(YOUR_SYSTEM_PROMPT, YOUR_CONTEXT_PROVIDER)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
